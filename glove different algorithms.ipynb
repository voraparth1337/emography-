{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import nltk.data\n",
    "from nltk.tokenize import word_tokenize\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-1e466b2b116e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GoogleNews-vectors-negative300.bin.gz\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_sims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/parth/anaconda3/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvector_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msyn0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatatype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0madd_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = KeyedVectors.load_word2vec_format(\"glove_wv_twitter_200d.txt\", binary=False)  \n",
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('tweets_labelled',skipinitialspace=True, skip_blank_lines=True,encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index2word_set = set(model.wv.index2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_tweets( text ):\n",
    "    # clean_1 = BeautifulSoup(text,\"lxml\").get_text()\n",
    "    clean_2 = re.sub(\"[^a-zA-Z]\",\" \", text).lower().strip()\n",
    "    clean_3 = word_tokenize(clean_2)\n",
    "    stop_words = set(stopwords.words(\"english\")) - set(['and','or','not'])\n",
    "    words = [w for w in clean_3 if not w in stop_words]\n",
    "    return words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_features = 200\n",
    "\n",
    "def makeFeatureVec(words, num_features = 200):\n",
    "    global index2word_set\n",
    "    featureVec = np.zeros((num_features,),dtype=\"float32\")\n",
    "    nwords = 0.00000000001\n",
    "    for word in words:\n",
    "        # if the word is in wordset then add to feature vec\n",
    "        if word in index2word_set: \n",
    "            nwords = nwords + 1.\n",
    "            featureVec = np.add(featureVec,model[word])\n",
    "    \n",
    "    featureVec = np.divide(featureVec,nwords)\n",
    "    return featureVec\n",
    "\n",
    "def get_average_feature_vectors( tweets, num_features = 200 ):\n",
    "    counter = 0\n",
    "    tweetFeatureVecs = np.zeros((len(tweets),num_features),dtype=\"float32\")\n",
    "    \n",
    "    for tweet in tweets:\n",
    "        tweetFeatureVecs[counter] = makeFeatureVec(tweet, num_features)\n",
    "        counter += 1\n",
    "    \n",
    "    return tweetFeatureVecs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "start = time.time()\n",
    "\n",
    "cleaned_tweets = []\n",
    "for text in tweets['text']:\n",
    "    cleaned_tweets.append( clean_tweets(text))\n",
    "    \n",
    "DataVecs = get_average_feature_vectors( cleaned_tweets, num_features )\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "elapsed_cleaning = end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loading test data set\n",
    "\n",
    "f_test = open('test_1.txt','r')\n",
    "lines_test = [line.strip() for line in f_test]\n",
    "\n",
    "test = pd.DataFrame(data = {'text':lines_test})\n",
    "\n",
    "cleaned_test_tweets = []\n",
    "for text in test['text']:\n",
    "    cleaned_test_tweets.append( clean_tweets(text))\n",
    "    \n",
    "testDataVecs = get_average_feature_vectors( cleaned_test_tweets, num_features )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting k means...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "import time\n",
    "\n",
    "start = time.time() # Start time\n",
    "gnb = GaussianNB()\n",
    "gnb = gnb.fit( trainDataVecs , train[\"emotion\"] )\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "elapsed_training = end - start\n",
    "print('starting k means...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = gnb.predict( testDataVecs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for item in result:\n",
    "    if item == 4:\n",
    "        counter+=1\n",
    "\n",
    "a = len(testDataVecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer.. and lower and without beautiful soap \n",
      "200d twitter trained glove model\n",
      "Naive Bayes\n",
      "time taken cleaning 42.063427209854126\n",
      "time taken training 0.3242208957672119\n",
      "67.65833817547937\n"
     ]
    }
   ],
   "source": [
    "print('tokenizer.. and lower and without beautiful soap ')\n",
    "print(\"200d twitter trained glove model\")\n",
    "print(\"Naive Bayes\")\n",
    "print(\"time taken cleaning \"+ str(elapsed_cleaning))\n",
    "print(\"time taken training \"+ str(elapsed_training))\n",
    "print(counter/a*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting k means...\n",
      "end..\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "import time\n",
    "\n",
    "start = time.time() # Start time\n",
    "gnb = BernoulliNB()\n",
    "print('starting k means...')\n",
    "gnb = gnb.fit( trainDataVecs , train[\"emotion\"] )\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "elapsed_training = end - start\n",
    "print('end..')\n",
    "\n",
    "result = gnb.predict( testDataVecs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer.. and lower and without beautiful soap \n",
      "200d twitter trained glove model\n",
      "Bernoulli Naive Bayes\n",
      "time taken cleaning 42.063427209854126\n",
      "time taken training 0.6897268295288086\n",
      "64.43927948866937\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for item in result:\n",
    "    if item == 4:\n",
    "        counter+=1\n",
    "\n",
    "a = len(testDataVecs)\n",
    "\n",
    "print('tokenizer.. and lower and without beautiful soap ')\n",
    "print(\"200d twitter trained glove model\")\n",
    "print(\"Bernoulli Naive Bayes\")\n",
    "print(\"time taken cleaning \"+ str(elapsed_cleaning))\n",
    "print(\"time taken training \"+ str(elapsed_training))\n",
    "print(counter/a*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting k means...\n",
      "end..\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import time\n",
    "\n",
    "start = time.time() # Start time\n",
    "gnb = DecisionTreeClassifier()\n",
    "print('starting decision tree...')\n",
    "gnb = gnb.fit( trainDataVecs , train[\"emotion\"] )\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "elapsed_training = end - start\n",
    "print('end..')\n",
    "\n",
    "result = gnb.predict( testDataVecs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer.. and lower and without beautiful soap \n",
      "200d twitter trained glove model\n",
      "Decision Tree Classifier\n",
      "time taken cleaning 42.063427209854126\n",
      "time taken training 49.926862955093384\n",
      "58.12899477048228\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for item in result:\n",
    "    if item == 4:\n",
    "        counter+=1\n",
    "\n",
    "a = len(testDataVecs)\n",
    "\n",
    "print('tokenizer.. and lower and without beautiful soap ')\n",
    "print(\"200d twitter trained glove model\")\n",
    "print(\"Decision Tree Classifier\")\n",
    "print(\"time taken cleaning \"+ str(elapsed_cleaning))\n",
    "print(\"time taken training \"+ str(elapsed_training))\n",
    "print(counter/a*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting decision tree...\n",
      "end..\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import time\n",
    "\n",
    "# Start time\n",
    "start = time.time() \n",
    "gnb = AdaBoostClassifier( base_estimator=, n_estimators=300)\n",
    "print('starting decision tree...')\n",
    "gnb = gnb.fit( trainDataVecs , train[\"emotion\"] )\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "elapsed_training = end - start\n",
    "print('end..')\n",
    "\n",
    "result = gnb.predict( testDataVecs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer.. and lower and without beautiful soap \n",
      "200d twitter trained glove model\n",
      "Adaboost Classifier 100 estimators\n",
      "time taken cleaning 42.063427209854126\n",
      "time taken training 718.6130969524384\n",
      "70.12202208018594\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for item in result:\n",
    "    if item == 4:\n",
    "        counter+=1\n",
    "\n",
    "a = len(testDataVecs)\n",
    "\n",
    "print('tokenizer.. and lower and without beautiful soap ')\n",
    "print(\"200d twitter trained glove model\")\n",
    "print(\"Adaboost Classifier 200 estimators\")\n",
    "print(\"time taken cleaning \"+ str(elapsed_cleaning))\n",
    "print(\"time taken training \"+ str(elapsed_training))\n",
    "print(counter/a*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer.. and lower and without beautiful soap \n",
      "200d twitter trained glove model\n",
      "Adaboost Classifier 300 estimators\n",
      "time taken cleaning 42.063427209854126\n",
      "time taken training 1091.0529487133026\n",
      "72.13248111563044\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for item in result:\n",
    "    if item == 4:\n",
    "        counter+=1\n",
    "\n",
    "a = len(testDataVecs)\n",
    "\n",
    "print('tokenizer.. and lower and without beautiful soap ')\n",
    "print(\"200d twitter trained glove model\")\n",
    "print(\"Adaboost Classifier 300 estimators\")\n",
    "print(\"time taken cleaning \"+ str(elapsed_cleaning))\n",
    "print(\"time taken training \"+ str(elapsed_training))\n",
    "print(counter/a*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting decision tree...\n",
      "end..\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "import time\n",
    "\n",
    "# Start time\n",
    "start = time.time() \n",
    "gnb = BaggingClassifier(n_estimators=100)\n",
    "print('starting decision tree...')\n",
    "gnb = gnb.fit( trainDataVecs , train[\"emotion\"] )\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "elapsed_training = end - start\n",
    "print('end..')\n",
    "\n",
    "result = gnb.predict( testDataVecs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer.. and lower and without beautiful soap \n",
      "200d twitter trained glove model\n",
      "Adaboost Classifier 300 estimators\n",
      "time taken cleaning 42.063427209854126\n",
      "time taken training 54.480804506937666\n",
      "74.7356188262638\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for item in result:\n",
    "    if item == 4:\n",
    "        counter+=1\n",
    "\n",
    "a = len(testDataVecs)\n",
    "\n",
    "print('tokenizer.. and lower and without beautiful soap ')\n",
    "print(\"200d twitter trained glove model\")\n",
    "print(\"Adaboost Classifier 300 estimators\")\n",
    "print(\"time taken cleaning \"+ str(elapsed_cleaning))\n",
    "print(\"time taken training \"+ str(elapsed_training/60))\n",
    "print((counter/a*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting decision tree...\n",
      "end..\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import time\n",
    "\n",
    "# Start time\n",
    "start = time.time() \n",
    "gnb = ExtraTreesClassifier(n_estimators=100)\n",
    "print('starting decision tree...')\n",
    "gnb = gnb.fit( trainDataVecs , train[\"emotion\"] )\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "elapsed_training = end - start\n",
    "print('end..')\n",
    "\n",
    "result = gnb.predict( testDataVecs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer.. and lower and without beautiful soap \n",
      "200d twitter trained glove model\n",
      "Adaboost Classifier 300 estimators\n",
      "time taken cleaning 42.063427209854126\n",
      "time taken training 0.9425798694292704\n",
      "77.76873910517142\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for item in result:\n",
    "    if item == 4:\n",
    "        counter+=1\n",
    "\n",
    "a = len(testDataVecs)\n",
    "\n",
    "print('tokenizer.. and lower and without beautiful soap ')\n",
    "print(\"200d twitter trained glove model\")\n",
    "print(\"Adaboost Classifier 300 estimators\")\n",
    "print(\"time taken cleaning \"+ str(elapsed_cleaning))\n",
    "print(\"time taken training \"+ str(elapsed_training/60))\n",
    "print((counter/a*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting decision tree...\n",
      "end..\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import time\n",
    "\n",
    "# Start time\n",
    "start = time.time() \n",
    "gnb = ExtraTreesClassifier(n_estimators=250)\n",
    "print('starting decision tree...')\n",
    "gnb = gnb.fit( trainDataVecs , train[\"emotion\"] )\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "elapsed_training = end - start\n",
    "print('end..')\n",
    "\n",
    "result = gnb.predict( testDataVecs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer.. and lower and without beautiful soap \n",
      "200d twitter trained glove model\n",
      "Extra trees classifier with n = 250\n",
      "time taken cleaning 42.063427209854126\n",
      "time taken training 2.136068264643351\n",
      "79.37245787332947\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for item in result:\n",
    "    if item == 4:\n",
    "        counter+=1\n",
    "\n",
    "a = len(testDataVecs)\n",
    "\n",
    "print('tokenizer.. and lower and without beautiful soap ')\n",
    "print(\"200d twitter trained glove model\")\n",
    "print(\"Extra trees classifier with n = 250\")\n",
    "print(\"time taken cleaning \"+ str(elapsed_cleaning))\n",
    "print(\"time taken training \"+ str(elapsed_training/60))\n",
    "print((counter/a*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting decision tree...\n",
      "end..\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import time\n",
    "\n",
    "# Start time\n",
    "start = time.time() \n",
    "gnb = ExtraTreesClassifier(n_estimators=400)\n",
    "print('starting decision tree...')\n",
    "gnb = gnb.fit( trainDataVecs , train[\"emotion\"] )\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "elapsed_training = end - start\n",
    "print('end..')\n",
    "\n",
    "result = gnb.predict( testDataVecs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer.. and lower and without beautiful soap \n",
      "200d twitter trained glove model\n",
      "Extra trees classifier with n = 400\n",
      "time taken cleaning 41.324188470840454\n",
      "time taken training 3.7100925842920938\n",
      "79.8954096455549\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for item in result:\n",
    "    if item == 4:\n",
    "        counter+=1\n",
    "\n",
    "a = len(testDataVecs)\n",
    "\n",
    "print('tokenizer.. and lower and without beautiful soap ')\n",
    "print(\"200d twitter trained glove model\")\n",
    "print(\"Extra trees classifier with n = 400\")\n",
    "print(\"time taken cleaning \"+ str(elapsed_cleaning))\n",
    "print(\"time taken training \"+ str(elapsed_training/60))\n",
    "print((counter/a*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting decision tree...\n",
      "end..\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import time\n",
    "\n",
    "# Start time\n",
    "start = time.time() \n",
    "gnb = GradientBoostingClassifier( n_estimators = 5 )\n",
    "print('starting decision tree...')\n",
    "gnb = gnb.fit( trainDataVecs , train[\"emotion\"] )\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "elapsed_training = end - start\n",
    "print('end..')\n",
    "\n",
    "result = gnb.predict( testDataVecs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer.. and lower and without beautiful soap \n",
      "200d twitter trained glove model\n",
      "GradientBoostingClassifier with n = 5 \n",
      "time taken cleaning 41.324188470840454\n",
      "time taken training 1.4412586212158203\n",
      "40.267286461359674\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for item in result:\n",
    "    if item == 4:\n",
    "        counter+=1\n",
    "\n",
    "print('tokenizer.. and lower and without beautiful soap ')\n",
    "print(\"200d twitter trained glove model\")\n",
    "print(\"GradientBoostingClassifier with n = 5 \")\n",
    "print(\"time taken cleaning \"+ str(elapsed_cleaning))\n",
    "print(\"time taken training \"+ str(elapsed_training/60))\n",
    "print((counter/a*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting decision tree...\n",
      "end..\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import time\n",
    "\n",
    "# Start time\n",
    "start = time.time() \n",
    "gnb = GradientBoostingClassifier( n_estimators = 200)\n",
    "print('starting decision tree...')\n",
    "gnb = gnb.fit( trainDataVecs , train[\"emotion\"] )\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "elapsed_training = end - start\n",
    "print('end..')\n",
    "\n",
    "result = gnb.predict( testDataVecs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer.. and lower and without beautiful soap \n",
      "200d twitter trained glove model\n",
      "GradientBoostingClassifier with n = 200 \n",
      "time taken cleaning 41.324188470840454\n",
      "time taken training 54.058541655540466\n",
      "80.89482858803021\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for item in result:\n",
    "    if item == 4:\n",
    "        counter+=1\n",
    "\n",
    "print('tokenizer.. and lower and without beautiful soap ')\n",
    "print(\"200d twitter trained glove model\")\n",
    "print(\"GradientBoostingClassifier with n = 200 \")\n",
    "print(\"time taken cleaning \"+ str(elapsed_cleaning))\n",
    "print(\"time taken training \"+ str(elapsed_training/60))\n",
    "print((counter/a*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler_2 = StandardScaler()\n",
    "\n",
    "scaler.fit(trainDataVecs)\n",
    "scaler_2.fit(testDataVecs)\n",
    "\n",
    "scaled_features = scaler.transform(trainDataVecs)\n",
    "scaled_features_2 = scaler_2.transform(testDataVecs)\n",
    "\n",
    "train_data = pd.DataFrame(scaled_features)\n",
    "test_data = pd.DataFrame(scaled_features_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.536281</td>\n",
       "      <td>0.184717</td>\n",
       "      <td>-1.021303</td>\n",
       "      <td>-0.025466</td>\n",
       "      <td>0.731627</td>\n",
       "      <td>-0.540282</td>\n",
       "      <td>-0.415373</td>\n",
       "      <td>1.108405</td>\n",
       "      <td>0.176077</td>\n",
       "      <td>-0.140699</td>\n",
       "      <td>...</td>\n",
       "      <td>0.560534</td>\n",
       "      <td>-0.337678</td>\n",
       "      <td>0.226749</td>\n",
       "      <td>-0.012622</td>\n",
       "      <td>-0.124013</td>\n",
       "      <td>0.077854</td>\n",
       "      <td>-0.416690</td>\n",
       "      <td>-0.915452</td>\n",
       "      <td>-1.314554</td>\n",
       "      <td>0.272701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.515645</td>\n",
       "      <td>0.668908</td>\n",
       "      <td>-0.533410</td>\n",
       "      <td>0.450628</td>\n",
       "      <td>-1.392717</td>\n",
       "      <td>1.915446</td>\n",
       "      <td>0.402510</td>\n",
       "      <td>1.793945</td>\n",
       "      <td>0.217540</td>\n",
       "      <td>0.357952</td>\n",
       "      <td>...</td>\n",
       "      <td>1.077824</td>\n",
       "      <td>1.334954</td>\n",
       "      <td>-0.234815</td>\n",
       "      <td>-0.441147</td>\n",
       "      <td>-0.356302</td>\n",
       "      <td>0.290673</td>\n",
       "      <td>0.029758</td>\n",
       "      <td>-0.098941</td>\n",
       "      <td>0.639460</td>\n",
       "      <td>-1.704955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.242393</td>\n",
       "      <td>-1.559132</td>\n",
       "      <td>0.397846</td>\n",
       "      <td>-0.394267</td>\n",
       "      <td>0.656731</td>\n",
       "      <td>-0.296408</td>\n",
       "      <td>0.221417</td>\n",
       "      <td>-0.920436</td>\n",
       "      <td>-0.210945</td>\n",
       "      <td>-1.202649</td>\n",
       "      <td>...</td>\n",
       "      <td>1.166860</td>\n",
       "      <td>-1.351027</td>\n",
       "      <td>0.209995</td>\n",
       "      <td>1.167535</td>\n",
       "      <td>0.592785</td>\n",
       "      <td>0.216706</td>\n",
       "      <td>0.339014</td>\n",
       "      <td>-0.429476</td>\n",
       "      <td>-0.362713</td>\n",
       "      <td>-0.244046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.186894</td>\n",
       "      <td>-0.687733</td>\n",
       "      <td>-1.174927</td>\n",
       "      <td>0.239706</td>\n",
       "      <td>0.912271</td>\n",
       "      <td>0.048455</td>\n",
       "      <td>-2.106123</td>\n",
       "      <td>0.141005</td>\n",
       "      <td>1.105161</td>\n",
       "      <td>0.937508</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.279585</td>\n",
       "      <td>0.994043</td>\n",
       "      <td>0.095342</td>\n",
       "      <td>0.383181</td>\n",
       "      <td>0.338533</td>\n",
       "      <td>1.213106</td>\n",
       "      <td>-0.745737</td>\n",
       "      <td>-0.240227</td>\n",
       "      <td>0.895378</td>\n",
       "      <td>-2.470921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.640856</td>\n",
       "      <td>1.532695</td>\n",
       "      <td>-0.129433</td>\n",
       "      <td>-0.203702</td>\n",
       "      <td>-1.282778</td>\n",
       "      <td>0.247234</td>\n",
       "      <td>-0.139036</td>\n",
       "      <td>2.152618</td>\n",
       "      <td>-0.792155</td>\n",
       "      <td>-0.668611</td>\n",
       "      <td>...</td>\n",
       "      <td>0.209759</td>\n",
       "      <td>0.732104</td>\n",
       "      <td>0.430684</td>\n",
       "      <td>-0.495618</td>\n",
       "      <td>-2.033121</td>\n",
       "      <td>0.199986</td>\n",
       "      <td>0.588196</td>\n",
       "      <td>-0.801340</td>\n",
       "      <td>0.875809</td>\n",
       "      <td>-0.934488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  1.536281  0.184717 -1.021303 -0.025466  0.731627 -0.540282 -0.415373   \n",
       "1  1.515645  0.668908 -0.533410  0.450628 -1.392717  1.915446  0.402510   \n",
       "2 -0.242393 -1.559132  0.397846 -0.394267  0.656731 -0.296408  0.221417   \n",
       "3  0.186894 -0.687733 -1.174927  0.239706  0.912271  0.048455 -2.106123   \n",
       "4  1.640856  1.532695 -0.129433 -0.203702 -1.282778  0.247234 -0.139036   \n",
       "\n",
       "        7         8         9      ...          190       191       192  \\\n",
       "0  1.108405  0.176077 -0.140699    ...     0.560534 -0.337678  0.226749   \n",
       "1  1.793945  0.217540  0.357952    ...     1.077824  1.334954 -0.234815   \n",
       "2 -0.920436 -0.210945 -1.202649    ...     1.166860 -1.351027  0.209995   \n",
       "3  0.141005  1.105161  0.937508    ...    -0.279585  0.994043  0.095342   \n",
       "4  2.152618 -0.792155 -0.668611    ...     0.209759  0.732104  0.430684   \n",
       "\n",
       "        193       194       195       196       197       198       199  \n",
       "0 -0.012622 -0.124013  0.077854 -0.416690 -0.915452 -1.314554  0.272701  \n",
       "1 -0.441147 -0.356302  0.290673  0.029758 -0.098941  0.639460 -1.704955  \n",
       "2  1.167535  0.592785  0.216706  0.339014 -0.429476 -0.362713 -0.244046  \n",
       "3  0.383181  0.338533  1.213106 -0.745737 -0.240227  0.895378 -2.470921  \n",
       "4 -0.495618 -2.033121  0.199986  0.588196 -0.801340  0.875809 -0.934488  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting KNN\n",
      "end..\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-9ab9dfa15f36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'end..'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/parth/anaconda3/lib/python3.6/site-packages/sklearn/neighbors/classification.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mneigh_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/parth/anaconda3/lib/python3.6/site-packages/sklearn/neighbors/base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    379\u001b[0m                 delayed(self._tree.query, check_pickle=False)(\n\u001b[1;32m    380\u001b[0m                     X[s], n_neighbors, return_distance)\n\u001b[0;32m--> 381\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m             )\n\u001b[1;32m    383\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/parth/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    766\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/parth/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/parth/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    680\u001b[0m                 \u001b[0;31m# check if timeout supported in backend future implementation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m'timeout'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgetfullargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/parth/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/parth/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/parth/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/parth/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = time.time() \n",
    "knn = KNeighborsClassifier(n_neighbors=1, n_jobs=-1)\n",
    "print('starting KNN')\n",
    "knn.fit( train_data , train[\"emotion\"] )\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "elapsed_training = end - start\n",
    "print('end..')\n",
    "\n",
    "result = knn.predict( test_data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
